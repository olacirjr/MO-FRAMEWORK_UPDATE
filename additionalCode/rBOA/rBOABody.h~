/*#############################################################
  ##                                                         ##
  ##                       rBOA_Body.h                       ##
  ##           -------------------------------------         ##
  ##             Copyright (c) 2004 Chang Wook Ahn           ##
  ##     Gwangju Institute of Science & Technology (GIST)    ##
  ##                                                         ##
  ##                Main Work:  rBOA operation               ##
  ##                                                         ##
  ##  rBOA exploits Bayesian factorization by mixture models.##
  ##  Mixture models employ K-means algorithm.               ##
  ##  Find the substructure by extracting the maximally      ##
  ##    connected component from the resulting graph.        ##
  ##  Each subproblem is fitted by normal mixture            ##
  ##    distributions by employing the leader algorithm.     ##
  ##  Offspring are generated by independently sampling each ##
  ##    substructure and recomining partial individuals,     ##
  ##    which are building blocks in the continuous domain.  ##
  ##  Thereby, it can realise proper decomposition of        ##
  ##    a given problem and the probabilistic BB crossover.  ##
  ##                                                         ##
  #############################################################*/
 

/********************************************************************/
/**                  Global variables                              **/ 
/********************************************************************/

/* Variables used by the operators in this library */

/*======== Variables for clustering individuals on the problem space iteself ==========*/
int       maxNumClustersWholeProblem, **wholeClusters, *wholeClustersSize, whole_clustersUsed, whole_clustersUsedOverall;

/*===================== Variables of problem structures ===============*/
int        **pi, *piLen, *omega;
double     ***logarithmicProbNew, **logarithmicProbCurrent, ***d_new_family, ***d_new_parents, **d_current_family, **d_current_parents;

/*================== Variables for problem statistics =================*/
Vector    *mu;
Matrix    *sigma_check;

/*============== Variables of subspace based clusters =================*/
int       ***clusters, **clustersSize, *clustersUsed, *clustersUsedOverall;
double    **alpha;

/*=================== Variables of subproblems ========================*/
int       SubProblemsSize, *SubProblemsLen, **SubProblems;

/*=============== Variables of managing subproblems ===================*/
int       ***pi_sub, **piLen_sub, **omega_sub;
Vector    **mu_sub, **mu_sub_tilde, **sigma_sub_tilde;
Matrix    **sigma_sub_check, **sigma_sub_i;

/*======================== Auxiliary Variables ========================*/
int       *sci, scilen;

/*================ Variables for sampling individuals =================*/
short      haveNextNextGaussian = 0;
double    nextNextGaussian;


/************************************************************************
 *
 * Function prototypes.
 *
 ***********************************************************************/

void rBOA( int, double, int );

/*
 * Uses rBOA to generate new solutions. First, a model is
 * selected (learned from the selected solutions).
 * Secondly, new solutions are generated by sampling them
 * from the estimated probabilistic model.
 */
void clusteringWholeProblem( void);
void modelSelection( void );
void decomposeProblem( void );
void clusteringSubproblems( int, double, int );
void modelFitting( void );
void generateNewSolutions( void );

void rBOA( int useClusters, double leaderThreshold, int maximumAmountOfClusters )
{
    int maxNumClustersWholeProblem=numMixComponents, wholeClusters[maxNumClustersWholeProblem][selsize],
	wholeClustersSize[maxNumClustersWholeProblem], whole_clustersUsed, whole_clustersUsedOverall=0;

    clusteringWholeProblem();

     modelSelection();

    decomposeProblem();

    clusteringSubproblems( useClusters, leaderThreshold, maximumAmountOfClusters);

    modelFitting();

    generateNewSolutions();
}

/*&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&*/
/* Clustering is performed for detecting nonlinearity of variables
 * by summing BIC of piece-wise linearly seperated data.
 */
void memoryAllocationForClusteringWholeProblem( int );
void Kmeans( int );

void clusteringWholeProblem()
{
    /*--- maxNumClustersWholeProblem, leaderThresholdWholeProblem are golbal variables. ---*/
    maxNumClustersWholeProblem = numMixComponents;

    //if( !wholeClusters ) {
    //    memoryAllocationForClusteringWholeProblem( maxNumClustersWholeProblem );
    //}
    
    Kmeans( maxNumClustersWholeProblem );
}

void memoryAllocationForClusteringWholeProblem( int maxNumClustersWholeProblem )
{
    int i;
    whole_clustersUsedOverall = 0;
    wholeClusters = (int **) Malloc( maxNumClustersWholeProblem * sizeof( int * ) );
    wholeClustersSize = (int *) Malloc( maxNumClustersWholeProblem * sizeof( int ) );

    for( i = 0; i < maxNumClustersWholeProblem; i++ )
        wholeClusters[i] = (int *) Malloc( selsize * sizeof( int ) );;
}


double EuclidicDistanceCentroidSample(int, double *, int);

int find_min(int, double *);
double calc_new_centroid(int, int *, int);

void Kmeans( int maxnumClustersWholeProblem )
{
    int i, j, cluster_id, Iter, MaxIter;
    int stringLen, DataSize;

    stringLen = stringlength;
    DataSize = selsize;
        
    bool flag;
    double **old_centroid, **new_centroid, *Distances;

    if( maxNumClustersWholeProblem == 1 )
        MaxIter = 1;
    else
        MaxIter = 5;

    /****** Memory Allocation *******/
    Distances = (double *) Malloc( maxNumClustersWholeProblem*sizeof( double ) );
    old_centroid = (double **) Malloc( maxNumClustersWholeProblem*sizeof( double * ) );
    new_centroid = (double **) Malloc( maxNumClustersWholeProblem*sizeof( double * ) );
    for( i=0; i<maxNumClustersWholeProblem; i++ ) {
        old_centroid[i] = (double *) Malloc( stringLen*sizeof( double ) );
        new_centroid[i] = (double *) Malloc( stringLen*sizeof( double ) );
    }

    // Randomly Choose the new central point.
    bool flag1 = true;
    int *init_central_pos;
    init_central_pos = (int *) Malloc( maxNumClustersWholeProblem * sizeof( int ) );
    init_central_pos[0] = RANDOMNUMBER( selsize );
    for( i=1; i<maxNumClustersWholeProblem; i++ ) {
        flag1 = true;
        while(flag1) {
            flag1 = false;
            init_central_pos[i] = RANDOMNUMBER( selsize );

            for( j=0; j<i; j++ ) {
                if( init_central_pos[i] == init_central_pos[j] )
                    flag1 = true;
            }
        }
    }

    ///////// Periodically Choose ////////////
    for( i=0; i<maxNumClustersWholeProblem; i++ ) {
        for( j=0; j<stringLen; j++ ) {
            new_centroid[i][j] = GETREALSELECTED( j, init_central_pos[i]); 
            old_centroid[i][j] = 0.0;
        }
    }

    free( init_central_pos);


    /////////////////////////////////////////////////////////////////////////
    ////////////////////  Start K-means Clustering  /////////////////////////
    /////////////////////////////////////////////////////////////////////////
    flag = true;
    Iter = 0;

    while( flag ) {
       
        /*** initialization of wholeClusters & wholeClustersSize ***/
        for( i=0; i<maxNumClustersWholeProblem; i++ ) {
            wholeClustersSize[i] = 0;
            for( j=0; j<selsize; j++ )
                wholeClusters[i][j] = 0;
        }
        /**************** End of the Initilization ****************/
        
        for( i=0; i<DataSize; i++ ) {
            for( j=0; j<maxNumClustersWholeProblem; j++ ) {         
                Distances[j]=EuclidicDistanceCentroidSample(stringLen, new_centroid[j], i);
            }
            
            cluster_id = find_min( maxNumClustersWholeProblem, Distances );             
            wholeClusters[ cluster_id ][ wholeClustersSize[cluster_id] ] = i;           
            wholeClustersSize[cluster_id]++;            
        }
        
        for( i=0; i<maxNumClustersWholeProblem; i++ ) {
            for( j=0; j<stringLen; j++ ) {
                old_centroid[i][j] = new_centroid[i][j];
                new_centroid[i][j] = calc_new_centroid(j, wholeClusters[i], wholeClustersSize[i]);
            }
        }
        Iter++;

        if( Iter > MaxIter ) flag = false;
    }



    /****** Memory Deallocation ******/
    free( Distances );
    for( i=0; i<maxNumClustersWholeProblem; i++ ) {
        free (old_centroid[i]);
        free (new_centroid[i]);
    }
    free(old_centroid);
    free(new_centroid);
    
    whole_clustersUsed = maxNumClustersWholeProblem;
}

double EuclidicDistanceCentroidSample(int stringLen, double *centroid, int sample_idx ) {
    double value, result;
    value = 0.0; result = 0.0;
    for( int i=0; i<stringLen; i++ ) {
        value = centroid[i] - GETREALSELECTED( i, sample_idx );
        result += (value*value);
    }
    return( result );
}

int find_min( int NumClusters, double *Distances ) {
    int min_idx=0;
    double min = Distances[0];  
    for( int i=1; i<NumClusters; i++ ) {
        if( Distances[i] < min ) {
            min = Distances[i];
            min_idx = i;
        }
    }
    return( min_idx );
}

double calc_new_centroid(int string_idx, int *cluster_set, int cluster_set_size) {
    double value = 0;
    
    for( int i=0; i<cluster_set_size; i++ ) {
        value += GETREALSELECTED( string_idx, cluster_set[i] );
    }
    value = value/(double)cluster_set_size;
    return( value );
}
/************************* End Of the K-means Clustering ****************************/
/************************************************************************************/

/*&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&*/


/*
 * Model selection in this implementation of rBOA
 * involves learning conditional factorizations
 * in a multiple of clusters. The samples are
 * clustered first. When no clustering should be
 * used, a single cluster is created containing
 * all of the samples.
 */
void allocateMemoryForGeneralStructures( void );
void factorizationSelection( void );
void modelSelection()
{ 
    if ( !pi ) {
        allocateMemoryForGeneralStructures();
    }
    factorizationSelection();
}

/*
 * Allocates memory for the clusters as well as the
 * parent vectors and sample orderings for the
 * conditional factorization in each cluster.
 */
void allocateMemoryForGeneralStructures()
{
  int i;
  pi                  = (int **) Malloc( stringlength*sizeof( int * ) );
  piLen               = (int *) Malloc( stringlength*sizeof( int ) );
  omega               = (int *) Malloc( stringlength*sizeof( int ) );

  for( i = 0; i < stringlength; i++ )
  {
    pi[i] = (int *) Malloc( stringlength * sizeof( int ) );
  }
}


/*
 * Learning a conditional normal factorization in a specified
 * cluster.
 */
int  addArc( int, int, short **, int **, int *, int **, int * );
void findArc( short **, int *, int *, int * );
void initializeLogarithmicsConditional( void );
void updateLogarithmicsConditional( int, int, short **, int **, int * );
void topologicalSort( int **, int * );
void save_model( void );

void factorizationSelection()
{
  short **allowed;
  int     i, j, **vp, *vpLen, **vs, *vsLen, gamma, v0, v1;

  /* Marking the arcs that may still be added to the
   * DAG that represents the conditional factorization,
   * is done in the allowed[] array */
  allowed = (short **) Malloc( stringlength*sizeof( short * ) );
  for( i = 0; i < stringlength; i++ )
    allowed[i] = (short *) Malloc( stringlength*sizeof( short ) );

  vpLen = (int *) Malloc( stringlength*sizeof( int ) );
  vsLen = (int *) Malloc( stringlength*sizeof( int ) );
  vp    = (int **) Malloc( stringlength*sizeof( int * ) );
  vs    = (int **) Malloc( stringlength*sizeof( int * ) );
  for( i = 0; i < stringlength; i++ )
  {
    vp[i]    = (int *) Malloc( stringlength*sizeof( int ) );
    vs[i]    = (int *) Malloc( stringlength*sizeof( int ) );
    vpLen[i] = 0;
    vsLen[i] = 0;
  }

  /* Initially all arcs, except self loops, are allowed */
  for( i = 0; i < stringlength; i++ )
  {
    for( j = 0; j < stringlength; j++ ) {
      allowed[i][j] = 1;
    }
    allowed[i][i] = 0;
  }

  initializeLogarithmicsConditional();


  /* The amount of arcs that is still addable is denoted by gamma */
  gamma = stringlength*stringlength - stringlength;

  /* If no parents are allowed, we shouldn't start the algorithm */
  if( kappa <= 0 )
    gamma = 0;

  while( gamma > 0 )
  {
    findArc( allowed, vpLen, &v0, &v1 );

    if( v0 < 0 )
      break;

    gamma -= addArc( v0, v1, allowed, vp, vpLen, vs, vsLen );

    updateLogarithmicsConditional( v0, v1, allowed, vp, vpLen );
  }

  /* Perform topological sort to get sample ordering */
  topologicalSort( vp, vpLen );

  for( i = 0; i < stringlength; i++ )
  {
    free( vp[i] );
    free( vs[i] );
    free( allowed[i] );
  }
  free( vpLen );
  free( vsLen );
  free( vp );
  free( vs );
  free( allowed );

  save_model(); // Save prababilistic model.
}

void save_model( )
{
    int i, j;

    if( saveModel )
    {
        FILE *fp;
        if( (fp=fopen("learned_model", "a" )) == NULL )
            printf( "File should not be opened!\n" );

        if( generation==0 )     fprintf( fp, "\nNew Iteration starts here!\n" );
        fprintf( fp, "Current Generation: %d\n", generation);

        for( i = 0; i < stringlength; i++ )
        {
            fprintf(fp, "omega(%2d) = %2d, pi(%2d) = (", i, omega[i], omega[i]);
            for( j = 0; j < piLen[omega[i]]-1; j++ )
                fprintf(fp, "%d,", pi[omega[i]][j]);
            if( piLen[omega[i]] > 0 )
                fprintf(fp, "%d", pi[omega[i]][piLen[omega[i]]-1]);
            fprintf(fp, ")\n");
        }
        fprintf(fp,"\n");
        fclose(fp);
    }
}

/*
 * Computes a topological sort on the DAG that
 * represents the conditional factorization.
 * the result is placed in the omega vector
 * that represents a valid sampling order.
 */
int  topologicalSortVisit( int **, int *, int, short *, int );
void topologicalSort( int **vp, int *vpLen )
{
  int    i, j, z;
  short *m;

  m = (short *) Malloc( stringlength*sizeof( short ) );
  for( i = 0; i < stringlength; i++ )
  {
    m[i]              = 0;
    piLen[i] = vpLen[i];
    for( j = 0; j < vpLen[i]; j++ )
      pi[i][j] = vp[i][j];
  }

  z = stringlength - 1;

  for( i = 0; i < stringlength; i++ )
  {
    if( !m[i] )
      z = topologicalSortVisit( vp, vpLen, i, m, z );
  }

  free( m );
}

/*
 * Part of the topological sort, a visit to a node.
 */
int topologicalSortVisit( int **vp, int *vpLen, int i, short *m, int z )
{
  int j;

  m[i] = 1;
  for( j = 0; j < vpLen[i]; j++ )
    if( !m[vp[i][j]] )
      z = topologicalSortVisit( vp, vpLen, vp[i][j], m, z );
  omega[z] = i;

  return( z - 1 );
}

/*
 * Iterates over all possible arcs that can be
 * added to the DAG that represents the conditional
 * factorization and computes the change
 * in the penalized negative log-likelihood
 * after a splice. The arc that results in
 * the largest decrease is returned in the
 * pointer variables v0 and v1 (v0 -> v1).
 */
double computeArcChange( int, int, int * );
void findArc( short **allowed, int *vpLen, int *v0, int *v1 )
{
  int    i, j, imax, jmax, pos1, pos2, swap, *order;
  double delta, deltamax;

  deltamax = 0;
  imax     = -1;
  jmax     = -1;

  order = (int *) Malloc( stringlength*sizeof( int ) );
  for( i = 0; i < stringlength; i++ )
    order[i] = i;
  for( i = 0; i < stringlength/2; i++ )
  {
    pos1        = RANDOMNUMBER( stringlength );
    pos2        = RANDOMNUMBER( stringlength );
    swap        = order[pos1];
    order[pos1] = order[pos2];
    order[pos2] = swap;
  }

  /* Investigate all allowed arc operations in a random order */
  for( i = 0; i < stringlength; i++ )
    for( j = 0; j < stringlength; j++ )
    {
      if( allowed[order[i]][order[j]] )
      {
        delta = computeArcChange( order[i], order[j], vpLen );

        if( delta > deltamax )
        {
          deltamax = delta;
          imax     = order[i];
          jmax     = order[j];
        }
      }
    }

  *v0 = imax;
  *v1 = jmax;

  free( order );
}

/*
 * Computes the change in the penalized negative log-likelihood
 * (according to the approximate Bayesian Information Criterion
 * (BIC)) when an arc (v0 -> v1) is added to the conditional
 * factorization.
 */
double negativeLogLikelihoodDifference( int, int );
double amountOfParametersParents( int, int * );
double amountOfParametersFamily( int, int * );
double computeArcChange( int v0, int v1, int *vpLen )
{
  double result;

  /* Negative log--likelihood difference */
  result = negativeLogLikelihoodDifference( v0, v1 );

  /* Parameter difference, approximate Bayesian Information Criterion */
  result += 0.5*log(selsize)*amountOfParametersParents( v1, vpLen );
  result -= 0.5*log(selsize)*amountOfParametersFamily( v1, vpLen );
    
  double tmp1 = 0.0, tmp2 = 0.0;
  for( int i=0; i<whole_clustersUsed; i++){
    tmp1 += logarithmicProbNew[i][v0][v1];
    tmp2 += logarithmicProbCurrent[i][v1];
  }
  
  return( result );
}

/*
 * Returns the negative log-likelihood difference
 * between the conditional pdf after addition of
 * an arc and before the addition 
 * when the data are clustered on the whole space.
 */
double negativeLogLikelihoodDifference( int v0, int v1 )
{
  int i;
  double logLikelihood = 0.0;
  
  for( i=0; i<whole_clustersUsed; i++ )
    logLikelihood += ( logarithmicProbNew[i][v0][v1] - logarithmicProbCurrent[i][v1] );
  
  return( logLikelihood );
}

/*
 * Returns the amount of parameters required to estimate the
 * full joint probability over the parent variables of
 * a certain variable when the data are clustered on the whole space.
 */
double normalJointPDFParameters( int );
double amountOfParametersParents( int v, int *vpLen )
{
  return( ((double) whole_clustersUsed) * normalJointPDFParameters( vpLen[v] ) );
}

/*
 * Returns the amount of parameters required to estimate the
 * full joint probability over all variables involved in the
 * conditional probability of a certain variable
 * when the data are clustered on the whole space.
 */
double amountOfParametersFamily( int v, int *vpLen )
{
  return( ((double) whole_clustersUsed) * normalJointPDFParameters( 1+vpLen[v] ) );
}

/*
 * Returns the amount of parameters that have
 * to be estimated in order to fit a specified
 * multivariate joint pdf (factor in the factorization).
 */
double normalJointPDFParameters( int amountOfParameters )
{
  double n;

  n = (double) amountOfParameters;

  return( 0.5*n*n + 1.5*n );
}

/*
 * To search the space of conditional factorizations
 * using the greedy arc addition algorithm, we require
 * to store and correctly manipulate the negative
 * log-likelihood values. Here, these values are
 * initialized for all of the combinations of adding
 * an arc to the univariate factorization.
 */
void initializeLogarithmicsConditional()
{
  int c, i, j, k;

  /* Possibly initialize memory for likelihoods */
  if( !logarithmicProbCurrent )
  {
    logarithmicProbCurrent = (double **) Malloc( maxNumClustersWholeProblem * sizeof( double * ) );
    logarithmicProbNew = (double ***) Malloc( maxNumClustersWholeProblem * sizeof( double ** ) );

    for( i = 0; i < maxNumClustersWholeProblem; i++ )
    {
        logarithmicProbCurrent[i] = (double *) Malloc( stringlength*sizeof( double ) );
        logarithmicProbNew[i]     = (double **) Malloc( stringlength*sizeof( double * ) );

        for( j = 0; j < stringlength; j++ )
            logarithmicProbNew[i][j] = (double *) Malloc( stringlength*sizeof( double ) );
    }
  }

  /* Possibly initialize memory for normal pdf variables, clusterwise */
  if( !mu )
  {
    mu  = (Vector *) Malloc( maxNumClustersWholeProblem * sizeof( Vector ) );
    sigma_check = (Matrix *) Malloc( maxNumClustersWholeProblem * sizeof( Matrix ) );
    
    for( i = 0; i < maxNumClustersWholeProblem; i++ ) {
        mu[i]               = Vector_new( stringlength );
        sigma_check[i]      = Matrix_new( stringlength, stringlength );
    }
  }

  /* Possibly initialize memory for normal pdf determinants */
  if( !d_new_family )
  {
    d_current_family    = (double **) Malloc( maxNumClustersWholeProblem * sizeof( double * ) );
    d_current_parents   = (double **) Malloc( maxNumClustersWholeProblem * sizeof( double * ) );
    d_new_family        = (double ***) Malloc( maxNumClustersWholeProblem * sizeof( double ** ) );
    d_new_parents       = (double ***) Malloc( maxNumClustersWholeProblem * sizeof( double ** ) );

    for( i = 0; i < maxNumClustersWholeProblem; i++ ) 
    {
        d_current_family[i]  = (double *) Malloc( stringlength*sizeof( double ) );
        d_current_parents[i] = (double *) Malloc( stringlength*sizeof( double ) );
        d_new_family[i]      = (double **) Malloc( stringlength*sizeof( double * ) );
        d_new_parents[i]     = (double **) Malloc( stringlength*sizeof( double * ) );
        
        for( j = 0; j < stringlength; j++ )
        {
            d_new_family[i][j]  = (double *) Malloc( stringlength*sizeof( double ) );
            d_new_parents[i][j] = (double *) Malloc( stringlength*sizeof( double ) );
        }
    }
  }

  /*+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*/
  /* To compute Conditional entropy, first calculate MEAN and COVARIANCE     */
  /*+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*/
  
  /* Compute means for each cluster */
  for( c = 0; c < whole_clustersUsed; c++ ) {
    for( i = 0; i < stringlength; i++ )
    {
        mu[c][i] = 0.0;
        for( k = 0; k < wholeClustersSize[c]; k++ )
            mu[c][i] += GETREALSELECTED( i, wholeClusters[c][k] );
        mu[c][i] /= (double) wholeClustersSize[c];
    }
  }

  /* Compute covariances for each cluster */
  for( c = 0; c < whole_clustersUsed; c++ ) {
    for( i = 0; i < stringlength; i++ )
        for( j = i; j < stringlength; j++ )
        {
            sigma_check[c][i][j] = 0.0;
            
            for( k = 0; k < wholeClustersSize[c]; k++ ) {
                sigma_check[c][i][j] += GETREALSELECTED( i, wholeClusters[c][k] ) * GETREALSELECTED( j, wholeClusters[c][k] );
        }
        sigma_check[c][i][j] = sigma_check[c][i][j] / ((double) wholeClustersSize[c]) - mu[c][i]*mu[c][j];

        sigma_check[c][j][i] = sigma_check[c][i][j];
    }
  }
  /*+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*/

  /*
   * Compute the logarithmics for each index for the univariate (current)
   * factorization. Because of maximum likelihood estimation, the
   * average negative log--likelihood is the differential entropy.
   */
  for( c = 0; c < whole_clustersUsed; c++ )
  {
    for( i = 0; i < stringlength; i++ )
    {
        d_current_family[c][i]       = sigma_check[c][i][i];
        d_current_parents[c][i]      = 0.0;
        logarithmicProbCurrent[c][i] = -((double) wholeClustersSize[c])*0.5*(1.0 + SAFELOG(2.0*PI*d_current_family[c][i]));
    }
  }

  /*
   * Compute the logarithmics for each index for the new situtation in
   * which an arc has been added. Again, the average negative
   * log--likelihood is the differential entropy. logarithmicProbNew[i][j]
   * is the addition of arc Y_{i} -> Y_{j}
   */
  for( c = 0; c < whole_clustersUsed; c++ )
  {
    for( i = 0; i < stringlength; i++ )
        for( j = 0; j < stringlength; j++ )
        if( i != j )
        {
            d_new_parents[c][i][j]      = d_current_family[c][i];
            d_new_family[c][i][j]       = sigma_check[c][j][j]*sigma_check[c][i][i] - sigma_check[c][j][i]*sigma_check[c][i][j];
            logarithmicProbNew[c][i][j] = -((double) wholeClustersSize[c])*0.5*(2.0 + SAFELOG(4.0*PI*PI*d_new_family[c][i][j])) - logarithmicProbCurrent[c][i];
        }
    }
  }

/*
 * To keep the organization of negative log--likelihood
 * values correct during the search operation, we have
 * to update the values (and locations) after
 * an arc addition has been performed.
 */
void updateLogarithmicsConditionalSingleNormalPDF( int, int, int **, int *, int );
void updateLogarithmicsConditional( int v0, int v1, short **allowed, int **vp, int *vpLen )
{
  int i, c;

  /* A parent v0 was added to node v1, so we update the negative
   * log-likelihood and determinant information with regard to each cluster. */
  
  for( c = 0; c < whole_clustersUsed; c++ )
  {
    logarithmicProbCurrent[c][v1] = logarithmicProbNew[c][v0][v1];

    d_current_family[c][v1]       = d_new_family[c][v0][v1];
    d_current_parents[c][v1]      = d_new_parents[c][v0][v1];
  }

  /* The likelihood information for all possible arcs incoming to v1
   * must be recomputed. */
  
  for( c = 0; c < whole_clustersUsed; c++ ) {
    for( i = 0; i < stringlength; i++ )
        if( allowed[i][v1] )
            updateLogarithmicsConditionalSingleNormalPDF( i, v1, vp, vpLen, c );
  }
}

/*
 * Computes the negative log-likelihood of the a certain
 * factor as well as the required determinant information.
 * Because of maximum likelihood estimation, the average
 * negative log--likelihood is the differential entropy of a given cluster.
 */
void updateLogarithmicsConditionalSingleNormalPDF( int vnew, int v1, int **vp, int *vpLen, int cluster_id )
{
  short  singular;
  int    j, l, k, *sci, scilen;
  Vector inverse, colvec;
  Matrix sigma;

  sigma = Matrix_new( vpLen[v1]+2, vpLen[v1]+2 );

  /* Find required part of covariance matrix */
  scilen = vpLen[v1]+2;
  sci    = (int *) Malloc( scilen*sizeof( int ) );
  sci[0] = v1;
  for( j = 1; j < scilen-1; j++ )
    sci[j] = vp[v1][j-1];
  sci[scilen-1] = vnew;

  for( j = 0; j < scilen; j++ )
  {
    for( l = 0; l <= j; l++ )
    {
      sigma[j][l] = sigma_check[cluster_id][sci[j]][sci[l]];
      sigma[l][j] = sigma[j][l];
    }
  }

  /* Solve linear system of equations */
  inverse   = Vector_new( vpLen[v1]+2 );
  colvec    = Vector_new( vpLen[v1]+2 );
  for( j = 0; j < vpLen[v1]+1; j++ )
    colvec[j] = 0.0;
  colvec[vpLen[v1]+1] = 1.0;

  Matrix_Square_Axb_waste_input_place_in( sigma, vpLen[v1]+2, colvec, inverse, &singular );

  /* Compute determinant and negative log-likelihood of the full joint pdf of data samples in cluster_id */
  d_new_family[cluster_id][vnew][v1]       = inverse[vpLen[v1]+1] == 0 ? 0 : d_current_family[cluster_id][v1]/inverse[vpLen[v1]+1];
  logarithmicProbNew[cluster_id][vnew][v1] = -((double)wholeClustersSize[cluster_id])*0.5*(vpLen[v1]+2+SAFELOG(pow(2*PI,vpLen[v1]+2)*d_new_family[cluster_id][vnew][v1]));
  
  for( k = 0; k < vpLen[v1]+2; k++ )
    free( sigma[k] );
  free( sigma );
  free( inverse );
  free( colvec );

  sigma = Matrix_new( vpLen[v1]+1, vpLen[v1]+1 );

  /* Find required part of covariance matrix */
  scilen = vpLen[v1]+1;
  for( j = 0; j < scilen-1; j++ )
    sci[j] = vp[v1][j];
  sci[scilen-1] = vnew;

  for( j = 0; j < scilen; j++ )
  {
    for( l = 0; l <= j; l++ )
    {
      sigma[j][l] = sigma_check[cluster_id][sci[j]][sci[l]];
      sigma[l][j] = sigma[j][l];
    }
  }

  /* Solve linear system of equations */
  inverse   = Vector_new( vpLen[v1]+1 );
  colvec    = Vector_new( vpLen[v1]+1 );
  for( j = 0; j < vpLen[v1]; j++ )
    colvec[j] = 0.0;
  colvec[vpLen[v1]] = 1.0;

  Matrix_Square_Axb_waste_input_place_in( sigma, vpLen[v1]+1, colvec, inverse, &singular );

  /* Compute determinant and negative log-likelihood of the conditional pdf */
  d_new_parents[cluster_id][vnew][v1]      = inverse[vpLen[v1]] == 0 ? 0 : d_current_parents[cluster_id][v1]/inverse[vpLen[v1]];
  logarithmicProbNew[cluster_id][vnew][v1] = logarithmicProbNew[cluster_id][vnew][v1] + ((double)wholeClustersSize[cluster_id])*0.5*(vpLen[v1]+1+SAFELOG(pow(2*PI,vpLen[v1]+1)*d_new_parents[cluster_id][vnew][v1]));
  
  free( sci );
  for( k = 0; k < vpLen[v1]+1; k++ )
    free( sigma[k] );
  free( sigma );
  free( inverse );
  free( colvec );
}

/*
 * Adds an arc to the conditional factorization graph and updates which
 * arcs are still allowed to be added without introducing cycles.
 */
int addArc( int v0, int v1, short **allowed, int **vp, int *vpLen, int **vs, int *vsLen )
{
  short *m;
  int    i, j, k, *successors, *predecessors, *stack, top, sucLen, preLen, delta, node;

  m            = (short *) Malloc( stringlength*sizeof( short ) );
  successors   = (int *) Malloc( stringlength*sizeof( int ) );
  predecessors = (int *) Malloc( stringlength*sizeof( int ) );
  stack        = (int *) Malloc( stringlength*stringlength*sizeof( int ) );

  delta = 0;
  /* Mark added edge */
  vs[v0][vsLen[v0]] = v1;
  vsLen[v0]++;
  vp[v1][vpLen[v1]] = v0;
  vpLen[v1]++;
  if( allowed[v0][v1] )
  {
    allowed[v0][v1] = 0;
    delta++;
  }

  /* Initialize depth-first search */
  for( i = 0; i < stringlength; i++ )
    m[i] = 0;

  /* Perform forward depth-first search to find successors */
  sucLen     = 0;
  top        = 0;
  stack[top] = v1;
  top++;
  while( top > 0 )
  {
    node = stack[top-1];
    top--;

    if( !m[node] )
    {
      m[node]            = 1;
      successors[sucLen] = node;
      sucLen++;
      for( k = 0; k < vsLen[node]; k++ )
      {
        stack[top] = vs[node][k];
        top++;
      }
    }
  }

  /* Perform backward depth-first search to find predecessors */
  preLen     = 0;
  top        = 0;
  stack[top] = v0;
  top++;
  while( top > 0 )
  {
    node = stack[top-1];
    top--;

    if( !m[node] )
    {
      m[node]              = 1;
      predecessors[preLen] = node;
      preLen++;
      for( k = 0; k < vpLen[node]; k++ )
      {
        stack[top] = vp[node][k];
        top++;
      }
    }
  }

  /* Perform check on combinations of successors and predecessors */
  for( i = 0; i < sucLen; i++ )
    for( j = 0; j < preLen; j++ )
      if( allowed[successors[i]][predecessors[j]] )
      {
        allowed[successors[i]][predecessors[j]] = 0;
        delta++;
      }

  /* Check for full nodes */
  if( vpLen[v1] == kappa )
  {
    for( i = 0; i < stringlength; i++ )
      if( allowed[i][v1] )
      {
        allowed[i][v1] = 0;
        delta++;
      }
  }

  free( m );
  free( successors );
  free( predecessors );
  free( stack );

  return( delta );
}

////////////////////////////// End of Linkage Learning ///////////////////////////////////////



//////////////////////////////////////////////////////////////////////////////////////////////
///////////////////////////// Problem Decomposition Part /////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////

void gatheringSubproblems( void );
void arrangeOmega( void );

void decomposeProblem() { //The function is defined at the early stage of this problem.
    
    int i, j;
    int DefaultFlag;

    if( !SubProblemsLen ) {
        SubProblemsLen = (int *) Malloc (stringlength * sizeof(int) );
        SubProblems    = (int **) Malloc (stringlength * sizeof(int *) );
        for( i = 0; i < stringlength; i++ )
            SubProblems[i] = (int *) Malloc (stringlength * sizeof(int) );
    }
    
    // Reinitialization of SubProblems and subproblemsLen.
    for( i = 0; i < stringlength; i++ ) {
        for( j = 0; j < stringlength; j++ ) {
            SubProblems[i][j] = 0;
        }
        SubProblemsLen[i] = 0;
    }
    /////////////////////////////////////////////////////

    DefaultFlag = 0;
    for( i = 0; i < (stringlength-1); i++ ) { // -1 (in the range) means that there is no parent of the root node.
        if( piLen[omega[i]] == 0 ) {
            DefaultFlag++;
        }
    }

    if( DefaultFlag == (stringlength-1) ) { // All variables are independent.
        SubProblemsSize = stringlength;
        for( i = 0; i < stringlength; i++ ) {
            SubProblemsLen[i] = 1;
            SubProblems[i][0] = i;
        }
    }
    else if( DefaultFlag == 0 ) { // All variables are dependent !!!
        SubProblemsSize = 1;
        SubProblemsLen[0] = stringlength;
        for( i = 0; i < stringlength; i++ ) {
            SubProblems[0][i] = i;
        }
    }
    else {
        gatheringSubproblems();
    }

    arrangeOmega();

}


void searchNodes( int, int ** );
void gatheringSubproblems() {
    
    // Here, "SubProblemsSize", "SubProblemsLen" and "SubProblems" are global variables

    int i, j;
    int **Table;

    int TmpVar, count;

    bool UniqueFlag;

    Table = (int **) Malloc( stringlength * sizeof( int * ) );
    for( i = 0; i < stringlength; i++ ) {
        Table[i] = (int *) Malloc( stringlength * sizeof( int ) );
        for( j = 0; j < stringlength; j++ ) {
            Table[i][j] = 0;
        }
    }
    ///////////////////////////////////////////////////////////////
    
    // For Depedent Variables
    for( i = 0; i < stringlength; i++ ) {
        for( j = 0; j < piLen[omega[i]]; j++ ) {
            Table[omega[i]][pi[omega[i]][j]] = 1;
            Table[pi[omega[i]][j]][omega[i]] = 1;
        }
    }
    // For Independent Variables
    for( i = 0; i < stringlength; i++ ) {
        TmpVar = 0;

        for( j = 0; j < stringlength; j++ ) {
            TmpVar += Table[i][j];
        }
        if( TmpVar == 0 ) { Table[i][i] = 1; }
    }
    //////////////////////////////////////////////////////

    SubProblemsSize = 0;
    
    for( i = 0; i < stringlength; i++ ) {
        count = 0;

        for( j = 0; j < stringlength; j++ ) {
            if( Table[i][j] == 1 ) {
                Table[i][j] = 0; 
                Table[j][i] = 0;

                if( count == 0 ) {
                    count++;

                    SubProblemsSize++;
                    SubProblems[SubProblemsSize-1][SubProblemsLen[SubProblemsSize-1]] = i;
                    SubProblemsLen[SubProblemsSize-1]++;
                }
                
                if( i != j) { // if variables are Dependent.
                    
                    UniqueFlag = true;
                    
                    for( int k = 0; k < SubProblemsLen[SubProblemsSize-1]; k++ ) {
                        if( SubProblems[SubProblemsSize-1][k] == j )
                            UniqueFlag = false;
                    }

                    if( UniqueFlag == true ) {
                    
                        SubProblems[SubProblemsSize-1][SubProblemsLen[SubProblemsSize-1]] = j;
                        SubProblemsLen[SubProblemsSize-1]++;
                                        
                        searchNodes( j, Table ); // Call Iterative Function
                    }
                }

            }
        }
    }

    // Memory Deallocation.
    for( i = 0; i < stringlength; i++ )
        free( Table[i] );
    free( Table );
}

void searchNodes( int Idx, int **Table ) {
    int k;

    bool UniqueFlag;
    
    for( k = 0; k < stringlength; k++ ) {
        if( Table[Idx][k] == 1 ) {
            Table[Idx][k] = 0; 
            Table[k][Idx] = 0;
            
            if( Idx == k ) { 
                printf("Error: Table structure is wrong!\n"); 
                exit(1); 
            } // Check whether the Table is constructed in an invalid manner.
            
            UniqueFlag = true;

            for( int l = 0; l < SubProblemsLen[SubProblemsSize-1]; l++ ) {
                if( SubProblems[SubProblemsSize-1][l] == k )
                    UniqueFlag = false;
            }

            if( UniqueFlag == true ) {
                SubProblems[SubProblemsSize-1][SubProblemsLen[SubProblemsSize-1]] = k;
                SubProblemsLen[SubProblemsSize-1]++;

                searchNodes( k, Table );
            }
        }
    }
}

/*----- Omega is also arranged on the basis of subproblems ------*/
void arrangeOmega() { 
    int i, j, k;
    int l;

    // Memory Allocation
    if( !omega_sub ) {        
        omega_sub = (int **) Malloc( stringlength*sizeof( int * ) );
        for( i = 0; i < stringlength; i++ ) {
            omega_sub[i] = (int *) Malloc( stringlength*sizeof( int ) );
        }

    }
    // Reinitialization of omega_sub.
    for( i = 0; i < stringlength; i++ ) {
        for( j = 0; j < stringlength; j++ ) {
            omega_sub[i][j] = 0;
        }
    }
    ///////////////////////////////////////////////////////////
        
    int *Idx;
    bool Flag = false;
    Idx = (int *) Malloc( SubProblemsSize * sizeof( int ) );

    for( i = 0; i < SubProblemsSize; i++ )
        Idx[i] = 0;

    for( j = (stringlength-1); j >= 0; j-- ) {

        for( l = 0; l < SubProblemsSize; l++ ) {

            for( k = 0; k < SubProblemsLen[l]; k++ ) {
                
                if( omega[j] == SubProblems[l][k] ) {
                        
                    omega_sub[l][Idx[l]] = omega[j];
                    
                    Idx[l]++;
                    
                    Flag = true;

                    break;
                }

            }
            
            if( Flag == true ) { Flag = false; break; }
        }
    }


    for( i = 0; i < SubProblemsSize; i++ ) 
        SubProblemsLen[i] = Idx[i]; // In case position is change, it is rearranged.

    free( Idx );


    /*----- Arrange variables of subproblem according to the order of omega ----*/
    for( i = 0; i < SubProblemsSize; i++ ) {
        for( j = 0; j < SubProblemsLen[i]; j++ ) {
            SubProblems[i][j] = omega_sub[i][j];
        }
    }

}



///////////////////////////////////////////////////////////////////////////////////////////
////////////////////////////// Clustering of Sub-Problems /////////////////////////////////
///////////////////////////////////////////////////////////////////////////////////////////

void memoryAllocationOfParameters( int );
void singleCluster( int );
void determineAlpha( int );
void fitnessBasedBENDLeader( int, double, int );
void clusteringSubproblems( int useClusters, double leaderThreshold, int maximumAmountOfClusters )
{   
    // Here, "SubProblemsSize", "SubProblemsLen" and "SubProblems" are global variables
    int i;

    /* If this is the first time, allocate memory for clusters and such */
    if( !clusters ) {
        memoryAllocationOfParameters( maximumAmountOfClusters );
    }

    for( i = 0; i < SubProblemsSize; i++ ) {
        if( !useClusters ) {
            singleCluster( i );
        }
        else {      
            fitnessBasedBENDLeader( i, leaderThreshold, maximumAmountOfClusters );
        }       
        determineAlpha( i );
    }
}

/*
 * Allocates memory for the clusters
 */
void memoryAllocationOfParameters( int maximumAmountOfClusters )
{
  int i, j;

  clustersUsedOverall = (int *) Malloc( stringlength*sizeof( int ) );
  clustersUsed        = (int *) Malloc( stringlength*sizeof( int ) );

  clusters            = (int ***) Malloc( stringlength*sizeof( int ** ) ); // For convenience, maximum size is assigned. (i.e., max. num. subproblem is the string length.)
  clustersSize        = (int ** ) Malloc( stringlength*sizeof( int * ) );
  alpha               = (double **) Malloc( stringlength*sizeof( double * ) );

  for( i = 0; i < stringlength; i++ )
  {
    clustersUsedOverall[i] = 0;

    clusters[i]       = (int **) Malloc( maximumAmountOfClusters*sizeof( int * ) );
    clustersSize[i]   = (int *) Malloc( maximumAmountOfClusters*sizeof( int ) );
    alpha[i]          = (double *) Malloc( maximumAmountOfClusters*sizeof( double ) );

    for( j = 0; j < maximumAmountOfClusters; j++ ) {
        clusters[i][j] = NULL;
    }
  }

}

/*
 * Generates a single cluster containing all of
 * the samples in the sample vector.
 */
void singleCluster( int IdxSubProblem )
{
  int i, idx;
  idx = IdxSubProblem;

  if( clustersUsedOverall[idx] == 0 )
  {
    clusters[idx][0] = (int *) Malloc( selsize*sizeof( int ) );
    clustersUsedOverall[idx]++;
  }

  clustersUsed[idx] = 1;
  for( i = 0; i < selsize; i++ ) {
    clusters[idx][0][i] = i;
  }
  clustersSize[idx][0] = selsize;
}

/*
 * Determines the mixing coefficients alpha_{i}.
 * Coeffecient alpha_{i} for cluster i is set
 * to the size of cluster i divided by the
 * total amount of samples (proportionally to the
 * cluster size).
 */
void determineAlpha( int IdxSubProblem )
{
  int i, idx;
  idx = IdxSubProblem;

  for( i = 0; i < clustersUsed[idx]; i++ )
    alpha[idx][i] = ((double) clustersSize[idx][i])/((double) selsize);
}

/*
 * The Fitness based BEND Leader algorithm.
 * This clustering algorithm is essentially the Leader algorithm
 */

double normalizedEuclidicDistanceSampleCentroidOfSubproblem( int, int, double *, double *, double * );
void fitnessBasedBENDLeader( int IdxSubProblem, double leaderThreshold, int maximumAmountOfClusters )
{
  // Here, "SubProblemsLen" and "SubProblems" are global variables....

  int idx = IdxSubProblem;
  int    i, j, k, *Os, *Oc, qs, cmin, *L;
  double value, dmin, distance, *sampleMin, *sampleMax, **Centroid, dist, dist2, maximumDistance;

  sampleMin = (double *) Malloc( SubProblemsLen[idx]*sizeof( double ) );
  sampleMax = (double *) Malloc( SubProblemsLen[idx]*sizeof( double ) );
  L         = (int *) Malloc( selsize*sizeof( int ) );

  Centroid = (double **) Malloc( maximumAmountOfClusters*sizeof (double *) );  
  for( i=0; i<maximumAmountOfClusters; i++ )
    Centroid[i] = (double *) Malloc( SubProblemsLen[idx]*sizeof( double ) );


  clustersUsed[idx]   = 0;

  Os = (int *) Malloc( selsize*sizeof( int ) );
  Oc = (int *) Malloc( selsize*sizeof( int ) );

  /* Compute minimum and maximum among the samples in each dimension */

  for( i = 0; i < SubProblemsLen[idx]; i++ )
  {
    sampleMin[i] = GETREALSELECTED( SubProblems[idx][i], 0 );
    sampleMax[i] = GETREALSELECTED( SubProblems[idx][i], 0 );
    for( j = 1; j < selsize; j++ )
    {
      value = GETREALSELECTED( SubProblems[idx][i], j );
      if( value < sampleMin[i] )
        sampleMin[i] = value;
      if( value > sampleMax[i] )
        sampleMax[i] = value;
    }
  }

  /* Compute approximate maximum distance */
  maximumDistance = 0;
  for( j = 0; j < selsize; j++ )
  {
    dist2 = 0;
    for( i = 0; i < SubProblemsLen[idx]; i++ )
    {
      dist   = sampleMax[i] - sampleMin[i];
      value  = GETREALSELECTED(SubProblems[idx][i],j)-sampleMin[i];
      dist2 += dist == 0 ? 0 : (value*value)/(dist*dist);
    }
    dist2 = SAFESQRT( dist2 );
    if( dist2 > maximumDistance )
      maximumDistance = dist2;

    dist2 = 0;
    for( i = 0; i < SubProblemsLen[idx]; i++ )
    {
      dist   = sampleMax[i] - sampleMin[i];
      value  = GETREALSELECTED(SubProblems[idx][i],j)-sampleMax[i];
      dist2 += dist == 0 ? 0 : (value*value)/(dist*dist);
    }
    dist2 = SAFESQRT( dist2 );
    if( dist2 > maximumDistance )
      maximumDistance = dist2;
  }

  
  /* Perform clustering by going over the samples
   * that are ordered by fitness.
   * The clustering method is something like
   * bend-leader and K-means clustering algorithms */
  for( i = 0; i < selsize; i++ )
    Os[i] = i;

  for( i = 0; i < selsize; i++ )
  { 
        qs = RANDOMNUMBER( selsize - i);

    for( j = 0; j < clustersUsed[idx]; j++ )
        Oc[j] = j;
    
    //dmin = leaderThreshold;
    dmin = 1.0;
    
    for( j = 0; j < clustersUsed[idx]; j++ )
    {
        distance = normalizedEuclidicDistanceSampleCentroidOfSubproblem( idx, Os[qs], Centroid[Oc[j]], sampleMin, sampleMax ) / maximumDistance ;

        if( distance < dmin )
        {
            dmin = distance;
            cmin = Oc[j];
        }
    }

    if( dmin < leaderThreshold || clustersUsed[idx] == maximumAmountOfClusters )
    {
        clusters[idx][cmin][clustersSize[idx][cmin]] = Os[qs];
        clustersSize[idx][cmin]++;
    }
    else if( dmin >= leaderThreshold && clustersUsed[idx] < maximumAmountOfClusters )
    {
        if( clustersUsed[idx] == clustersUsedOverall[idx] )
        {
            clusters[idx][clustersUsed[idx]] = (int *) Malloc( selsize*sizeof( int ) );
            clustersUsedOverall[idx]++;
        }

        for( k=0; k<SubProblemsLen[idx]; k++ ) {
            Centroid[clustersUsed[idx]][k] = GETREALSELECTED( SubProblems[idx][k], Os[qs] );
        }

        L[clustersUsed[idx]]                = Os[qs];
        clusters[idx][clustersUsed[idx]][0] = Os[qs];
        clustersSize[idx][clustersUsed[idx]] = 1;
        clustersUsed[idx]++;
    }
    else {
        printf("Error occurs when the clustering is performed (INVALID OPTION).\n");        
        exit(1);
    }
    
    Os[qs] = Os[selsize-i-1];
  }

  free( L );
  free( Os );
  free( Oc );
  free( sampleMin );
  free( sampleMax );


  for( i=0; i<maximumAmountOfClusters; i++ )
    free( Centroid[i] );
  free( Centroid );
}

double normalizedEuclidicDistanceSampleCentroidOfSubproblem( int IdxSubProblem, int index1, double *CenterSubProblem, double *sampleMin, double *sampleMax )
{
  // Here, "SubProblemsLen" and "SubProblems" are global variables...

  int    idx = IdxSubProblem;

  int    i;
  double value, dist, result;

  result = 0.0;
  for( i = 0; i < SubProblemsLen[idx]; i++ )
  {
    value   = GETREALSELECTED( SubProblems[idx][i], index1 ) - CenterSubProblem[i];
    dist    = sampleMax[i] - sampleMin[i];
    result += dist == 0 ? 0 : (value*value)/(dist*dist);
  }
  result = SAFESQRT( result );

  return( result );
}

////////////////////////////// End of Clustering for Sub-Problems ///////////////////////////


///////////////////////////////////////////////////////////////////////////////////////////
///////////////// Model Fitting based on Each cluster of Subproblem ///////////////////////
///////////////////////////////////////////////////////////////////////////////////////////

 /*
 * Estimates the final parameters of the conditional factorizations,
 * including the ones required for sampling new solutions.
 */

void calculationMeanVariance( int, int );
void singleClusterSubproblemModelFittingConditional( int, int );
void modelFitting() {
    // Here, "SubProblemsSize", "SubProblemsLen" and "SubProblems" are global variables...

    int i, j;

    /*------- Computing mean & variance for each subproblem -------------*/
    for( i = 0; i < SubProblemsSize; i++ ) {
        for( j = 0; j < clustersUsed[i]; j++ ) {
            calculationMeanVariance( i , j );
        }
    }


    /*------ Based on the first and second moments, fit each substructure -----*/
    for( i = 0; i < SubProblemsSize; i++ ) { // 합칠수도 있을듯.....
        for( j = 0; j < clustersUsed[i]; j++ ) {
            if( clustersSize[i][j] > 0 ) {
                singleClusterSubproblemModelFittingConditional( i , j );
            }
        }
    }

}

void calculationMeanVariance( int IdxSubProblem, int IdxCluster ) {
    // Here, "SubProblemsSize", "SubProblemsLen" and "SubProblems" are global variables...

    int i, j, k;

    /* Possibly initialize memory for normal pdf variables, clusterwise */
    if( !mu_sub )
    {
        mu_sub               = (Vector **) Malloc( stringlength*sizeof( Vector * ) ); //Because max. num of subproblem amounts to the string length.
        mu_sub_tilde         = (Vector **) Malloc( stringlength*sizeof( Vector * ) );

        sigma_sub_check      = (Matrix **) Malloc( stringlength*sizeof( Matrix * ) );
        sigma_sub_i          = (Matrix **) Malloc( stringlength*sizeof( Matrix * ) );
        sigma_sub_tilde      = (Vector **) Malloc( stringlength*sizeof( Vector * ) );

        for( i = 0; i < stringlength; i++ ) {
            mu_sub[i]            = (Vector *) Malloc( maximumAmountOfClusters*sizeof( Vector ) );
            mu_sub_tilde[i]      = (Vector *) Malloc( maximumAmountOfClusters*sizeof( Vector ) );

            sigma_sub_check[i]   = (Matrix *) Malloc( maximumAmountOfClusters*sizeof( Vector * ) );
            sigma_sub_i[i]       = (Matrix *) Malloc( maximumAmountOfClusters*sizeof( Vector * ) );
            sigma_sub_tilde[i]   = (Vector *) Malloc( maximumAmountOfClusters*sizeof( Vector ) );

            for( j = 0; j < maximumAmountOfClusters; j++ )
            {
                mu_sub[i][j]      = NULL;
                sigma_sub_i[i][j] = NULL;
            }
        }

    }

    /* Possibly initialize memory for normal pdf variables, single cluster */
    if( !(mu_sub[IdxSubProblem][IdxCluster]) )
    {
        mu_sub[IdxSubProblem][IdxCluster]          = Vector_new( stringlength ); //Because max. num of subproblem amounts to the string length.
        sigma_sub_check[IdxSubProblem][IdxCluster] = Matrix_new( stringlength, stringlength );
    }
    //////////////////// End Memory Allocation //////////////////////////

     /* Compute means for this cluster of this subproblem */
    for( i = 0; i < SubProblemsLen[IdxSubProblem]; i++ )
    {
        mu_sub[IdxSubProblem][IdxCluster][i] = 0.0;
        for( k = 0; k < clustersSize[IdxSubProblem][IdxCluster]; k++ ) {
            mu_sub[IdxSubProblem][IdxCluster][i] += GETREALSELECTED( SubProblems[IdxSubProblem][i], clusters[IdxSubProblem][IdxCluster][k] );
        }
        mu_sub[IdxSubProblem][IdxCluster][i] /= (double) clustersSize[IdxSubProblem][IdxCluster];
    }

    /* Compute covariances for this cluster of this subproblem */
    for( i = 0; i < SubProblemsLen[IdxSubProblem]; i++ ) {
        for( j = i; j < SubProblemsLen[IdxSubProblem]; j++ )
        {
            sigma_sub_check[IdxSubProblem][IdxCluster][i][j] = 0.0;
            for( k = 0; k < clustersSize[IdxSubProblem][IdxCluster]; k++ ) {
                sigma_sub_check[IdxSubProblem][IdxCluster][i][j] += GETREALSELECTED( SubProblems[IdxSubProblem][i], clusters[IdxSubProblem][IdxCluster][k] ) * GETREALSELECTED( SubProblems[IdxSubProblem][j], clusters[IdxSubProblem][IdxCluster][k] );
            }
            sigma_sub_check[IdxSubProblem][IdxCluster][i][j] = sigma_sub_check[IdxSubProblem][IdxCluster][i][j] / ((double) clustersSize[IdxSubProblem][IdxCluster]) - ( mu_sub[IdxSubProblem][IdxCluster][i]*mu_sub[IdxSubProblem][IdxCluster][j] );

          sigma_sub_check[IdxSubProblem][IdxCluster][j][i] = sigma_sub_check[IdxSubProblem][IdxCluster][i][j];
        }
    }

}

/*
 * Estimates the final parameters of a single conditional
 * factorization in a single cluster of each subproblem.
 */
int return_variable_idx_subproblem(int, int);

void singleClusterSubproblemModelFittingConditional( int IdxSubProblem, int IdxCluster )
{
  // Here, "SubProblemsLen" and "SubProblems" are global variables...

  short  singular;
  int    i, j, k, l;
  Vector colvec;
  Matrix sigma;

  int var_idx; //when finding sigma_tilde, it is needed for arranging varialbes.

  /* Allocate memory for data structures */
  if( !sci )
  { 
    sci    = (int *) Malloc( stringlength * sizeof( int ) );
    scilen = 0;
  }

  /* Allocate memory for new solution sampling parameters */
  if( !(sigma_sub_i[IdxSubProblem][IdxCluster]) )
  { 
    sigma_sub_i[IdxSubProblem][IdxCluster]     = Matrix_new( stringlength, stringlength );
    sigma_sub_tilde[IdxSubProblem][IdxCluster] = Vector_new( stringlength );  //Because max. num of subproblem amounts to the string length.
    mu_sub_tilde[IdxSubProblem][IdxCluster]    = Vector_new( stringlength );
  }
  //////////////////////////// END Memory Allocation //////////////////////////////

  /*
   * Compute inverse information and store for sample use.
   * Compute sigma values when needed using memoization.
   */
   
  for( i = 0; i < SubProblemsLen[IdxSubProblem]; i++ )
  {
    sigma = Matrix_new( piLen[omega_sub[IdxSubProblem][i]]+1, piLen[omega_sub[IdxSubProblem][i]]+1 );

    /* Find required part of covariance matrix */
    scilen = piLen[omega_sub[IdxSubProblem][i]] + 1;
    
    sci[0] = return_variable_idx_subproblem(IdxSubProblem, omega_sub[IdxSubProblem][i]);

    for( j = 1; j < scilen; j++ )
        sci[j] = return_variable_idx_subproblem( IdxSubProblem, pi[omega_sub[IdxSubProblem][i]][j-1] );
        
    for( j = 0; j < scilen; j++ )
    {
      for( l = 0; l <= j; l++ )
      {
        sigma[j][l] = sigma_sub_check[IdxSubProblem][IdxCluster][sci[j]][sci[l]];
        sigma[l][j] = sigma[j][l];
      }
    }

    /* Solve linear system of equations to compute inverse */    
    colvec            = Vector_new( piLen[omega_sub[IdxSubProblem][i]]+1 );
    colvec[0]         = 1.0;
    for( j = 1; j < piLen[omega_sub[IdxSubProblem][i]]+1; j++ )
      colvec[j] = 0.0;
    
    var_idx = return_variable_idx_subproblem(IdxSubProblem, omega_sub[IdxSubProblem][i]);
    Matrix_Square_Axb_waste_input_place_in( sigma, piLen[omega_sub[IdxSubProblem][i]]+1, colvec, sigma_sub_i[IdxSubProblem][IdxCluster][var_idx], &singular );
    
    sigma_sub_tilde[IdxSubProblem][IdxCluster][var_idx] = SAFESQRT(sigma_sub_i[IdxSubProblem][IdxCluster][var_idx][0]);
    if( sigma_sub_tilde[IdxSubProblem][IdxCluster][var_idx] == 0 )
      singular = 1;
    sigma_sub_tilde[IdxSubProblem][IdxCluster][var_idx] = sigma_sub_tilde[IdxSubProblem][IdxCluster][var_idx] == 0 ? 0 : 1.0 / sigma_sub_tilde[IdxSubProblem][IdxCluster][var_idx];

    /* Postpone computation of mu_tilde[IdxSubProblem][IdxCluster][omega[SubProblems[IdxSubProblem][i]]]:
     * need incremental sample data (see sampling) */

    for( k = 0; k < piLen[omega_sub[IdxSubProblem][i]]+1; k++ )
      free( sigma[k] );
    free( sigma );
    free( colvec );
  }
}

int return_variable_idx_subproblem(int IdxSubProblem, int variable_in) {
    int i, result_idx;
    
    for( i = 0; i < SubProblemsLen[IdxSubProblem]; i++ ) {
        if( SubProblems[IdxSubProblem][i] == variable_in ) {
            result_idx = i;
            break;
        }
    }
    
    if( i == SubProblemsLen[IdxSubProblem] ) {
        printf(" Error: Ther is no such a case!!!\n");
        exit(1);
    }

    return( result_idx );
}
/////////////////// End of Fitting Except for mu_sub_tilde ///////////////////////////


///////////////////////////////////////////////////////////////////////////////////////////
///////////////////////////// Generating New Individuals //////////////////////////////////
///////////////////////////////////////////////////////////////////////////////////////////


/*
 * Generates new solutions by substructure-wise (i.e., subproblem wise) sampling 
 *  from conditional mixture distribution on subspace of the problem
 */

void sampleSolutionFromMixture( int, int );
void generateNewSolutions()
{
  int i, j, k;

  /* Copy the top tau*n best samples to the population */
  for( i = 0; i < selsize; i++ ) {
    for( j = 0; j < stringlength; j++ ) {
      SETREAL( GETREALSELECTED(j,i), j, i );
    }
  }

  /* Fill the remainder of the n - tau*n positions in the
   * population with new samples */
   
    for( k = 0; k < SubProblemsSize; k++ ) { //Here, "SubProblemsSize" is a global variable..
        for( i = selsize; i < popsize; i++ ) {
            sampleSolutionFromMixture( k, i );
        }
    }
}

/*
 * Generates a single new solution. 
 */
void sampleSolutionFromConditionalFactorization( int IdxSubProblem, int which, int IdxCluster );
void sampleSolutionFromMixture( int IdxSubProblem, int which )
{
  int    idx = IdxSubProblem;

  int    i, IdxCluster;
  double cumul, randomvalue;

  /* Select a factorization based on the mixing parameters */
  cumul       = 0;
  randomvalue = RANDOM01();

  for( i = 0; i < clustersUsed[idx]; i++ )
  {
    cumul += alpha[idx][i];
    if( randomvalue <= cumul )
      break;
  }
  
  IdxCluster = i == clustersUsed[idx] ? i - 1 : i;

  /* Sample from that factorization */
  sampleSolutionFromConditionalFactorization( IdxSubProblem, which, IdxCluster );

}

/*
 * Generates new partial solution from a conditional
 * factorization for subproblems is sampled in the valid omega ordering.
 */
double sampleGaussian( double, double );
void sampleSolutionFromConditionalFactorization( int IdxSubProblem, int which, int IdxCluster )
{
  // Here, "SubProblemsLen" and "SubProblems" are global variables...

  int i, k;
  int var_idx1, var_idx2;

  for( i = 0; i < SubProblemsLen[IdxSubProblem]; i ++ )
  {
    var_idx1 = return_variable_idx_subproblem(IdxSubProblem, omega_sub[IdxSubProblem][i]);
    mu_sub_tilde[IdxSubProblem][IdxCluster][var_idx1] = mu_sub[IdxSubProblem][IdxCluster][var_idx1]*sigma_sub_i[IdxSubProblem][IdxCluster][var_idx1][0];
    
    for( k = 0; k < piLen[omega_sub[IdxSubProblem][i]]; k++ ) {
        var_idx2 = return_variable_idx_subproblem(IdxSubProblem, pi[omega_sub[IdxSubProblem][i]][k]);

      mu_sub_tilde[IdxSubProblem][IdxCluster][var_idx1] -= ( (GETREAL( pi[omega_sub[IdxSubProblem][i]][k], which ) - mu_sub[IdxSubProblem][IdxCluster][var_idx2]) * sigma_sub_i[IdxSubProblem][IdxCluster][var_idx1][k+1] );
    }

    mu_sub_tilde[IdxSubProblem][IdxCluster][var_idx1] = sigma_sub_i[IdxSubProblem][IdxCluster][var_idx1][0] == 0 ? 0 : mu_sub_tilde[IdxSubProblem][IdxCluster][var_idx1]/sigma_sub_i[IdxSubProblem][IdxCluster][var_idx1][0];

    if( fabs( sigma_sub_tilde[IdxSubProblem][IdxCluster][var_idx1] ) == 0 )
      SETREAL( GETREALSELECTED( omega_sub[IdxSubProblem][i], clusters[IdxSubProblem][IdxCluster][0] ), omega_sub[IdxSubProblem][i], which );
    else
      SETREAL( sampleGaussian( mu_sub_tilde[IdxSubProblem][IdxCluster][var_idx1], sigma_sub_tilde[IdxSubProblem][IdxCluster][var_idx1] ), omega_sub[IdxSubProblem][i], which );
  }
}

/*
 * Returns a random, Gaussian ("normally") distributed
 * value with mean mu and standard deviation sigma.
 */
double nextGaussian( void );
double sampleGaussian( double mu, double sigma )
{
  return( mu + sigma*nextGaussian() );
}

/*
 * Returns a random, Gaussian ("normally") distributed
 * value with mean 0 and standard deviation 1.
 */
double nextGaussian()
{
  double v1, v2, s, multiplier;

  if( haveNextNextGaussian )
  {
    haveNextNextGaussian = 0;

    return( nextNextGaussian );
  }
  else
  {
    do
    {
      v1 = 2 * (RANDOM01()) - 1;
      v2 = 2 * (RANDOM01()) - 1;
      s = v1 * v1 + v2 * v2;
    } while (s >= 1);

    multiplier           = SAFESQRT(-2 * log(s)/s);
    nextNextGaussian     = v2 * multiplier;
    haveNextNextGaussian = 1;

    return( v1 * multiplier );
  }
}
